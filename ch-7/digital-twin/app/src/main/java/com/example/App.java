/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package com.example;

import com.example.rebalancing.CustomStateRestoreListener;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.Topology;
import org.apache.kafka.streams.state.HostInfo;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Properties;

public class App {
    private static final Logger log = LoggerFactory.getLogger(App.class);

    public static void main(String[] args) {
        System.out.println("Kafka Windowed TimeStream Analysis");

        // Call the Topology Build to build the kafka Stream Topology
        //Topology topology = PatientMonitoringTopology.build(); // class method ClassName.methodName()

        // For RESTful API calls
        // Override the system properties
        // we allow the following system properties to be overridden
        String host = System.getProperty("host");
        Integer port = Integer.parseInt(System.getProperty("port"));
        String stateDir = System.getProperty("stateDir");
        String endpoint = String.format("%s:%s", host, port);

        // Properties to run kafka stream
        // set the required properties for running Kafka Streams
        Properties props = new Properties();
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, "dev-consumer");
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:29092");
        props.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "latest"); // not reading the earliest events in a topic-partition // only read the latest
        props.put(StreamsConfig.APPLICATION_SERVER_CONFIG, endpoint);
        props.put(StreamsConfig.STATE_DIR_CONFIG, stateDir);

        // is your state-store showing undesired old data? if Yes-> setup the below configuration
        //props.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE); // To enable the purgeable state store feature
        // This guarantees that the state stores will be consistently purged.
        // an example of setting the timestamp extractor using a streams config
        // note that we override this in our topology implementation, this is
        // just here for demonstration purposes
//        props.put(
//                StreamsConfig.DEFAULT_TIMESTAMP_EXTRACTOR_CLASS_CONFIG, WallclockTimestampExtractor.class);


        // --------------- build the topology and Start Streaming -----------------
        System.out.println("Starting Patient Monitoring System");
        //KafkaStreams streams = new KafkaStreams(topology, props);

        // How to improve the visibility of Kafka Stream Applicaiton
        // how to listen to rebalance triggers in our Kafka Streams application
        // Approach-01/ State Listener: To monitor Kafka Stream applications state
        // i.e. when a rebanacing is tiggered which is impctful for Stateful applicaitons
        // Example: @MailChimp, they has a speical matrix that gets incremented when a Rebalancing is triggered and they connect that to Promethues
        // Kafka Stream Applicaiton States:
        // (a) Created -> Not Running
        // (b)Created -> Running -> Error-> Pending Shutdown-> Not Running
        // (c)Created -> Running -> Reblancing -> Pending Shutdown -> Not Running

//        streams.setStateListener(
//                (oldState, newState) ->{
//                    if (newState.equals(KafkaStreams.State.REBALANCING)){
//                        log.info("Rebalancing due to application state changes");
//                    }
//                }
//        );

        // Approach-02/ State restore listener example
        //streams.setGlobalStateRestoreListener(new CustomStateRestoreListener());

        // close Kafka Streams when the JVM shuts down (e.g. SIGTERM)
        //Runtime.getRuntime().addShutdownHook(new Thread(streams::close));

        // clean up local state since many of the tutorials write to the same location
        // you should run this sparingly in production since it will force the state
        // store to be rebuilt on start up
        //streams.cleanUp();

        // start streaming!
        //streams.start();

        // ------------------ start the REST service --------------------------------
        HostInfo hostInfo = new HostInfo(host, port);
        //PatientMonitoringService service = new PatientMonitoringService(hostInfo, streams);
        //service.start();

    }
}
